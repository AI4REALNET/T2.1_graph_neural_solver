{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from gnn_powergrid.dataset.utils.graph_utils import prepare_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "\n",
    "path = pathlib.Path().resolve()\n",
    "BENCH_CONFIG_PATH = path / \"configs\" / (env_name + \".ini\")\n",
    "DATA_PATH = path / \"Datasets\" / env_name / \"DC\"\n",
    "LOG_PATH = path / \"lips_logs.log\"\n",
    "\n",
    "benchmark = PowerGridBenchmark(benchmark_path=DATA_PATH,\n",
    "                               benchmark_name=\"Benchmark4\",#\"DoNothing\",\n",
    "                               load_data_set=True,\n",
    "                               config_path=BENCH_CONFIG_PATH,\n",
    "                               log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(benchmark.train_dataset.size)\n",
    "print(benchmark._test_dataset.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\") # or \"cuda:0\" if you have any GPU\n",
    "train_loader, val_loader, test_loader, test_ood_loader = prepare_dataset(benchmark=benchmark, \n",
    "                                                                         batch_size=128, \n",
    "                                                                         device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[3584, 2], edge_index=[2, 6742], edge_attr=[6742], y=[3584, 1], edge_index_no_diag=[2, 4950], edge_attr_no_diag=[4950], ybus=[3584, 28], batch=[3584], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3584"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement `np.divide` in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class GPGinput_without_NN(MessagePassing):\n",
    "    \"\"\"Graph Power Grid Input layer\n",
    "\n",
    "    This is the input layer of GNN initialize the theta (voltage angles) with zeros and\n",
    "    updates them through power flow equation\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 ref_node,\n",
    "                 device=\"cpu\",\n",
    "                 ):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.theta = None\n",
    "        self.device = device\n",
    "        self.ref_node=ref_node\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \n",
    "        # Initialize the voltage angles (theta) with zeros\n",
    "        self.theta = torch.zeros_like(batch.y, dtype=batch.y.dtype)\n",
    "\n",
    "        # Compute a message and propagate it to each node, it does 3 steps\n",
    "        # 1) It computes a message (Look at the message function below)\n",
    "        # 2) It propagates the message using an aggregation (sum here)\n",
    "        # 3) It calls the update function which could be Neural Network\n",
    "        aggr_msg = self.propagate(batch.edge_index_no_diag,\n",
    "                                  y=self.theta,\n",
    "                                  edge_weights=batch.edge_attr_no_diag * 100.0\n",
    "                                 )\n",
    "        n_bus = batch.ybus.size()[1]\n",
    "        n_sub = n_bus / 2\n",
    "        # keep only the diagonal elements of the ybus 3D tensors\n",
    "        ybus = batch.ybus.view(-1, n_bus, n_bus) * 100.0\n",
    "        denominator = torch.hstack([ybus[i].diag() for i in range(len(ybus))]).reshape(-1,1)\n",
    "        # ybus = ybus * torch.eye(*ybus.shape[-2:], device=self.device).repeat(ybus.shape[0], 1, 1)\n",
    "        # denominator = ybus[ybus.nonzero(as_tuple=True)].view(-1,1)\n",
    "        \n",
    "        input_node_power = (batch.x[:,0] - batch.x[:,1]).view(-1,1)\n",
    "        numerator = input_node_power - aggr_msg\n",
    "        # out = (input_node_power - aggr_msg) / denominator\n",
    "        out = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator!=0)\n",
    "        out = torch.Tensor(out)\n",
    "\n",
    "        #we impose that reference node has theta=0\n",
    "        out = out.view(-1, n_bus, 1) - out.view(-1,n_bus,1)[:,self.ref_node].repeat_interleave(n_bus, 1).view(-1, n_bus, 1)\n",
    "        out = out.flatten().view(-1,1)\n",
    "        #we impose the not used buses to have theta=0\n",
    "        out[denominator==0] = 0\n",
    "        \n",
    "        # impose also the unused buses to have zero thetas\n",
    "        \n",
    "        \n",
    "        return numerator, denominator\n",
    "    \n",
    "    def message(self, y_j, edge_weights):\n",
    "        \"\"\"Compute the message that should be propagated\n",
    "        \n",
    "        This function compute the message (which is the multiplication of theta and \n",
    "        admittance matrix elements connecting node i to j)\n",
    "\n",
    "        Args:\n",
    "            y_j (_type_): the theta (voltage angle) value at a neighboring node j\n",
    "            edge_weights (_type_): corresponding edge_weight (admittance matrix element)\n",
    "\n",
    "        Returns:\n",
    "            _type_: active powers for each neighboring node\n",
    "        \"\"\"\n",
    "        tmp = y_j * edge_weights.view(-1,1)\n",
    "        return tmp\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        \"\"\"update function of message passing layers\n",
    "\n",
    "        We output directly the aggreated message (sum)\n",
    "\n",
    "        Args:\n",
    "            aggr_out (_type_): the aggregated message\n",
    "\n",
    "        Returns:\n",
    "            _type_: the aggregated message\n",
    "        \"\"\"\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_input = GPGinput_without_NN(ref_node=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3584, 1]) torch.float32\n",
      "torch.Size([3584, 1]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "num, denom = gnn_input(batch)\n",
    "print(num.shape, num.dtype)\n",
    "print(denom.shape, denom.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is :  (3584, 1)\n",
      "The array : \n",
      " [[ 0.03797239]\n",
      " [ 0.01980564]\n",
      " [-0.01046045]\n",
      " ...\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# numpy divide version\n",
    "out_numpy = np.divide(num, denom, out=np.zeros_like(num), where=denom!=0)\n",
    "print(\"The shape is : \", out_numpy.shape)\n",
    "print(\"The array : \\n\", out_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is :  torch.Size([3584, 1])\n",
      "The array : \n",
      " tensor([[ 0.0380],\n",
      "        [ 0.0198],\n",
      "        [-0.0105],\n",
      "        ...,\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# one way to do with torch\n",
    "out_torch = torch.divide(num, denom)\n",
    "out_torch[torch.isnan(out_torch)] = 0.\n",
    "print(\"The shape is : \", out_torch.shape)\n",
    "print(\"The array : \\n\", out_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape is :  torch.Size([3584, 1])\n",
      "The array : \n",
      " tensor([[ 0.0380],\n",
      "        [ 0.0198],\n",
      "        [-0.0105],\n",
      "        ...,\n",
      "        [ 0.0000],\n",
      "        [ 0.0000],\n",
      "        [ 0.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# second way to do with torch\n",
    "indices = torch.where(denom.flatten()!=0.)[0]\n",
    "out_torch_2 = torch.zeros_like(denom)\n",
    "out_torch_2[indices] = torch.divide(num[indices], denom[indices])\n",
    "print(\"The shape is : \", out_torch_2.shape)\n",
    "print(\"The array : \\n\", out_torch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(out_torch.numpy() - out_numpy) < 1e-7)\n",
    "print(np.sum(out_torch_2.numpy() - out_numpy) < 1e-7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
