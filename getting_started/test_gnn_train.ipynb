{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lips.benchmark.powergridBenchmark import PowerGridBenchmark\n",
    "from gnn_powergrid.dataset import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"l2rpn_case14_sandbox\"\n",
    "\n",
    "path = pathlib.Path().resolve().parent\n",
    "BENCH_CONFIG_PATH = path / \"configs\" / (env_name + \".ini\")\n",
    "DATA_PATH = path / \"Datasets\" / env_name / \"DC\"\n",
    "LOG_PATH = path / \"lips_logs.log\"\n",
    "\n",
    "benchmark = PowerGridBenchmark(benchmark_path=DATA_PATH,\n",
    "                               benchmark_name=\"Benchmark4\",#\"DoNothing\",\n",
    "                               load_data_set=True,\n",
    "                               config_path=BENCH_CONFIG_PATH,\n",
    "                               log_path=LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(benchmark.train_dataset.size)\n",
    "print(benchmark._test_dataset.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Train dataset*******\n",
      "Train data size: 100000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a315475f1664e819cb77d48bc88dd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Validation dataset*******\n",
      "Validation data size: 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9f13e3456c45f283fb177928b6c1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Test dataset*******\n",
      "Test data size : 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce34b9b9f2a4338a6095213e387fab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******OOD dataset*******\n",
      "OOD data size: 10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a657cc08ea4e490a9c67ae4a05b69680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[3584, 2], edge_index=[2, 6656], edge_attr=[6656], y=[3584, 1], edge_index_no_diag=[2, 4864], edge_attr_no_diag=[4864], ybus=[3584, 28], batch=[3584], ptr=[129])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # or \"cuda:0\" if you have any GPU\n",
    "train_loader, val_loader, test_loader, test_ood_loader = prepare_dataset(benchmark=benchmark, \n",
    "                                                                         batch_size=128, \n",
    "                                                                         device=device)\n",
    "batch = next(iter(test_loader))\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.ybus.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class GPGinput(MessagePassing):\n",
    "    def __init__(self,\n",
    "                 ref_node,\n",
    "                 device=\"cpu\"\n",
    "                 ):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.ref_node = ref_node\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, init_theta, batch):\n",
    "\n",
    "        aggr_msg = self.propagate(batch.edge_index_no_diag,\n",
    "                                  y=init_theta,\n",
    "                                  edge_weights=batch.edge_attr_no_diag * 100.0\n",
    "                                 )\n",
    "        \n",
    "        # keep only the diagonal elements of the ybus 3D tensors\n",
    "        n_bus = batch.ybus.size()[1]\n",
    "        n_sub = n_bus / 2\n",
    "        ybus = batch.ybus.view(-1, n_bus, n_bus) * 100.0\n",
    "        ybus = ybus * torch.eye(*ybus.shape[-2:], device=self.device).repeat(ybus.shape[0], 1, 1)\n",
    "        denominator = torch.hstack([ybus[i].diag() for i in range(len(ybus))]).reshape(-1,1)\n",
    "        \n",
    "        input_node_power = (batch.x[:,0] - batch.x[:,1]).view(-1,1)\n",
    "        numerator = input_node_power - aggr_msg\n",
    "        \n",
    "        indices = torch.where(denominator.flatten()!=0.)[0]\n",
    "        out = torch.zeros_like(denominator)\n",
    "        out[indices] = torch.divide(numerator[indices], denominator[indices])\n",
    "\n",
    "        #we impose that node 0 has theta=0\n",
    "        out = out.view(-1, n_bus, 1) - out.view(-1,n_bus,1)[:,self.ref_node].repeat_interleave(n_bus, 1).view(-1, n_bus, 1)\n",
    "        out = out.flatten().view(-1,1)\n",
    "        \n",
    "        # imposing theta=0 for the bus which are not used\n",
    "        out[denominator==0] = 0\n",
    "        \n",
    "        return out, aggr_msg\n",
    "    \n",
    "    def message(self, y_j, edge_weights):\n",
    "        tmp = y_j * edge_weights.view(-1,1)\n",
    "        return tmp\n",
    "    \n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "    \n",
    "class GPGintermediate(MessagePassing):\n",
    "    def __init__(self,\n",
    "                 ref_node,\n",
    "                 device=\"cpu\"):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.theta = None\n",
    "        self.ref_node = ref_node\n",
    "        self.device = device\n",
    "        \n",
    "    \n",
    "    def forward(self, batch, theta):\n",
    "        self.theta = theta\n",
    "        \n",
    "        aggr_msg = self.propagate(batch.edge_index_no_diag,\n",
    "                                  y=self.theta,\n",
    "                                  edge_weights=batch.edge_attr_no_diag * 100.0\n",
    "                                 )\n",
    "\n",
    "        n_bus = batch.ybus.size()[1]\n",
    "        # keep only the diagonal elements of the ybus 3D tensors for denominator part\n",
    "        ybus = batch.ybus.view(-1, n_bus, n_bus) * 100.0\n",
    "        # ybus = ybus * torch.eye(*ybus.shape[-2:], device=self.device).repeat(ybus.shape[0], 1, 1)\n",
    "        # denominator = ybus[ybus.nonzero(as_tuple=True)].view(-1,1)\n",
    "        denominator = torch.hstack([ybus[i].diag() for i in range(len(ybus))]).reshape(-1,1)\n",
    "        \n",
    "        input_node_power = (batch.x[:,0] - batch.x[:,1]).view(-1,1)\n",
    "        numerator = input_node_power - aggr_msg\n",
    "        # out = (input_node_power - aggr_msg) / denominator\n",
    "        indices = torch.where(denominator.flatten()!=0.)[0]\n",
    "        out = torch.zeros_like(denominator)\n",
    "        out[indices] = torch.divide(numerator[indices], denominator[indices])\n",
    "\n",
    "        #we impose that reference node has theta=0\n",
    "        out = out.view(-1, n_bus, 1) - out.view(-1,n_bus,1)[:,self.ref_node].repeat_interleave(n_bus, 1).view(-1, n_bus, 1)\n",
    "        out = out.flatten().view(-1,1)\n",
    "        #we impose the not used buses to have theta=0\n",
    "        out[denominator==0] = 0\n",
    "        \n",
    "        return out, aggr_msg\n",
    "\n",
    "    def message(self, y_i, y_j, edge_weights):\n",
    "        tmp = y_j * edge_weights.view(-1,1)\n",
    "        return tmp\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "class LocalConservationLayer(MessagePassing):\n",
    "    \"\"\"\n",
    "    Same as power equilibrium equations\n",
    "    \n",
    "    It can be also injected as inputs to the next layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr=\"add\")\n",
    "        self.thetas = None\n",
    "        \n",
    "    def forward(self, batch, thetas=None):\n",
    "        self.thetas = thetas\n",
    "\n",
    "        aggr_message = self.propagate(batch.edge_index,\n",
    "                                      y=self.thetas,\n",
    "                                      edge_weights=batch.edge_attr * 100)\n",
    "\n",
    "        input_node_power = (batch.x[:,0] - batch.x[:,1]).view(-1,1)\n",
    "        nodal_error = input_node_power - aggr_message\n",
    "\n",
    "        return nodal_error\n",
    "\n",
    "    def message(self, y_i, y_j, edge_weights):\n",
    "        tmp = y_j * edge_weights.view(-1,1)\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "from torch.nn import Module\n",
    "\n",
    "class GPGmodel(Module):\n",
    "    def __init__(self,\n",
    "                 ref_node,\n",
    "                 input_dim=2,\n",
    "                 output_dim=1,\n",
    "                 embedding_size=16,\n",
    "                 num_gnn_layers=10,\n",
    "                 device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.ref_node = ref_node\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_gnn_layers = num_gnn_layers\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "        self.embedding_layer = None\n",
    "        self.input_layer = None\n",
    "        self.lc_layer = None\n",
    "        self.inter_layers = None\n",
    "        self.decoding_layer = None\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        self.embedding_layer = Linear(self.input_dim, self.output_dim)\n",
    "        self.input_layer = GPGinput(ref_node=self.ref_node, device=self.device)\n",
    "        self.lc_layer = LocalConservationLayer()\n",
    "        self.inter_layer = GPGintermediate(ref_node=self.ref_node, device=self.device)\n",
    "        #self.inter_layers = ModuleList([GPGintermediate(device=self.device) for _ in range(self.num_gnn_layers)])\n",
    "        self.decoding_layer = Linear(self.output_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        errors = []\n",
    "        init_theta = self.embedding_layer(batch.x) # start by NN init\n",
    "        # init_theta = torch.zeros_like(batch.y, dtype=batch.y.dtype) # flat start \n",
    "        out, _ = self.input_layer(init_theta, batch)\n",
    "        nodal_error = self.lc_layer(batch, out)\n",
    "        errors.append(abs(nodal_error).sum())\n",
    "        \n",
    "        #for gnn_layer, lc_layer_ in zip(self.inter_layers, itertools.repeat(self.lc_layer)):\n",
    "        for _ in range(self.num_gnn_layers):\n",
    "            out, _ = self.inter_layer(batch, out)\n",
    "            nodal_error = self.lc_layer(batch, out)\n",
    "            errors.append(abs(nodal_error).sum())\n",
    "\n",
    "        # out = self.decoding_layer(out)\n",
    "        return out, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try input layer and local conservation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_theta = torch.zeros_like(batch.y, dtype=batch.y.dtype)\n",
    "input_layer = GPGinput(ref_node=0, device=\"cpu\")\n",
    "lc_layer = LocalConservationLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, msg = input_layer(init_theta=init_theta, batch=batch)\n",
    "nodal_error = lc_layer(batch, out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7121, dtype=torch.float64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodal_errors_batch = torch.stack(torch.chunk(abs(nodal_error.flatten()), 128))\n",
    "torch.sum(nodal_errors_batch.sum(dim=1)/14)/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.7121, dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above\n",
    "(abs(nodal_error).sum() / 14)/128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpg_model = GPGmodel(ref_node=0)\n",
    "gpg_model.to(device)\n",
    "gpg_model.to(batch.x.dtype)\n",
    "out, errors = gpg_model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_model(model,\n",
    "                train_loader,\n",
    "                optimizer,\n",
    "                val_loader=None,\n",
    "                epochs=10):\n",
    "    train_losses = list()\n",
    "    val_losses = list()\n",
    "    # loss_func = MSELoss()\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred, error = model(batch)\n",
    "            loss = error[-1]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #total_loss += (loss * len(batch.x))\n",
    "            total_loss += loss / 14\n",
    "            #total_loss /= len(batch)\n",
    "        total_loss = total_loss.item() / len(train_loader.dataset)\n",
    "\n",
    "        if val_loader is not None:\n",
    "            _, _, val_loss = eval_model(model, val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. val_theta loss: {:.4f}\".format(\n",
    "                epoch, total_loss, val_loss))\n",
    "        else:\n",
    "            print(\"Epoch {}. Loss: {:.4f}\".format(epoch, total_loss))\n",
    "        train_losses.append(total_loss)        \n",
    "\n",
    "    return model, train_losses, val_losses\n",
    "\n",
    "def eval_model(model, loader):\n",
    "    model.eval()\n",
    "    predictions = list()\n",
    "    observations = list()\n",
    "    total_loss = 0\n",
    "    #total_constraint = 0\n",
    "    # loss_func = MSELoss()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            data = batch.x\n",
    "            #pred, active_powers_bus = model(batch)\n",
    "            pred, errors = model(batch)\n",
    "            true = batch.y\n",
    "            # loss computed on local conservation\n",
    "            #constraint = loss_func(message, power_at_node.view(-1,1))\n",
    "            # loss = (power_at_node - active_powers_bus).norm(2)\n",
    "            # loss_2 = loss_func(pred, true)\n",
    "            # loss = loss_1 + loss_2\n",
    "            # loss = loss_func(pred, true)\n",
    "            loss = errors[-1]\n",
    "            #total_loss += loss * len(data)\n",
    "            total_loss += loss / 14\n",
    "            #total_constraint += constraint * len(data)\n",
    "            predictions.append(pred)\n",
    "            observations.append(true)\n",
    "    predictions = torch.vstack(predictions)\n",
    "    observations = torch.vstack(observations)\n",
    "    mean_loss = total_loss.item() / len(loader.dataset)\n",
    "    #total_constraint = total_constraint.item() / len(loader.dataset)\n",
    "    \n",
    "    return predictions, observations, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpg_model = GPGmodel(ref_node=0, num_gnn_layers=50, device=device)\n",
    "gpg_model.to(device)\n",
    "optimizer = torch.optim.Adam(gpg_model.parameters(), lr=6e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c93c0eb5e24ea5ba1f3fddaaa9d8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 9.5998. val_theta loss: 5.1224\n",
      "Epoch 1. Loss: 0.7958. val_theta loss: 0.0524\n",
      "Epoch 2. Loss: 0.0449. val_theta loss: 0.0519\n",
      "Epoch 3. Loss: 0.0450. val_theta loss: 0.0500\n",
      "Epoch 4. Loss: 0.0450. val_theta loss: 0.0503\n",
      "Epoch 5. Loss: 0.0451. val_theta loss: 0.0505\n",
      "Epoch 6. Loss: 0.0451. val_theta loss: 0.0507\n",
      "Epoch 7. Loss: 0.0451. val_theta loss: 0.0507\n",
      "Epoch 8. Loss: 0.0451. val_theta loss: 0.0507\n",
      "Epoch 9. Loss: 0.0450. val_theta loss: 0.0516\n"
     ]
    }
   ],
   "source": [
    "model, train_losses, val_losses = train_model(gpg_model, \n",
    "                                              train_loader, \n",
    "                                              optimizer, \n",
    "                                              val_loader, \n",
    "                                              epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, observations, mean_loss = eval_model(gpg_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [-1.3042],\n",
       "        [-4.4101],\n",
       "        ...,\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000],\n",
       "        [-1.3040],\n",
       "        [-4.4094],\n",
       "        ...,\n",
       "        [ 0.0000],\n",
       "        [ 0.0000],\n",
       "        [ 0.0000]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions * (180/pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0011)\n"
     ]
    }
   ],
   "source": [
    "MAPE = abs((observations - (predictions * (180/pi))) / (observations + 1e-5)).mean()\n",
    "print(MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.012845651\n",
      "MAPE:  0.0011300456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "print(\"MAE: \", mean_absolute_error((predictions*(180/pi)).cpu().numpy(), observations.cpu().numpy()))\n",
    "print(\"MAPE: \", mean_absolute_percentage_error((predictions*(180/pi)).cpu().numpy(), observations.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0af273a467f474f8f707226dcd1c0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gnn_powergrid.dataset.utils.graph_utils import get_all_active_powers\n",
    "from gnn_powergrid.dataset.utils.solver_utils import get_obs\n",
    "\n",
    "\n",
    "env, obs = get_obs(benchmark)\n",
    "\n",
    "my_predictions = {}\n",
    "p_ors_pred, p_exs_pred = get_all_active_powers(benchmark._test_dataset.data, \n",
    "                                               obs, \n",
    "                                               theta_bus=(predictions*(180/pi)).view(-1, obs.n_sub*2).cpu())\n",
    "my_predictions[\"p_or\"] = p_ors_pred\n",
    "my_predictions[\"p_ex\"] = p_exs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_or': array([[ 3.8463341e+01,  3.1221951e+01,  2.7378098e+01, ...,\n",
       "          5.2651076e+00,  2.6037907e-02, -2.5557652e+01],\n",
       "        [ 3.7183605e+01,  3.1110968e+01,  2.6624983e+01, ...,\n",
       "          8.4811983e+00,  6.0061453e-04, -2.3301374e+01],\n",
       "        [ 3.7648624e+01,  3.1921959e+01,  2.6158779e+01, ...,\n",
       "          1.7716627e+01,  4.3142732e-04, -2.7856489e+01],\n",
       "        ...,\n",
       "        [ 3.9061081e+01,  3.0917017e+01,  3.0640781e+01, ...,\n",
       "          1.2027138e+01, -1.3806812e+01, -3.3561333e+01],\n",
       "        [ 2.8853081e+01,  4.0230785e+01,  3.4583946e+01, ...,\n",
       "          8.5671606e+00, -1.2303131e+01, -2.7189844e+01],\n",
       "        [ 3.8149796e+01,  3.0641281e+01,  2.9780848e+01, ...,\n",
       "          6.3635674e+00, -1.1396524e+01, -2.8885117e+01]], dtype=float32),\n",
       " 'p_ex': array([[-3.8463341e+01, -3.1221951e+01, -2.7378098e+01, ...,\n",
       "         -5.2651076e+00, -2.6037907e-02,  2.5557652e+01],\n",
       "        [-3.7183605e+01, -3.1110968e+01, -2.6624983e+01, ...,\n",
       "         -8.4811983e+00, -6.0061453e-04,  2.3301374e+01],\n",
       "        [-3.7648624e+01, -3.1921959e+01, -2.6158779e+01, ...,\n",
       "         -1.7716627e+01, -4.3142732e-04,  2.7856489e+01],\n",
       "        ...,\n",
       "        [-3.9061081e+01, -3.0917017e+01, -3.0640781e+01, ...,\n",
       "         -1.2027138e+01,  1.3806812e+01,  3.3561333e+01],\n",
       "        [-2.8853081e+01, -4.0230785e+01, -3.4583946e+01, ...,\n",
       "         -8.5671606e+00,  1.2303131e+01,  2.7189844e+01],\n",
       "        [-3.8149796e+01, -3.0641281e+01, -2.9780848e+01, ...,\n",
       "         -6.3635674e+00,  1.1396524e+01,  2.8885117e+01]], dtype=float32)}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lips.evaluation.powergrid_evaluation import PowerGridEvaluation\n",
    "\n",
    "\n",
    "evaluation = PowerGridEvaluation.from_benchmark(benchmark)\n",
    "metrics = evaluation.evaluate(observations=benchmark._test_dataset.data, \n",
    "                              predictions=my_predictions, \n",
    "                              env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ML': {'MSE_avg': {'p_or': 0.043757639825344086,\n",
       "   'p_ex': 0.043757639825344086},\n",
       "  'MAE_avg': {'p_or': 0.054794203490018845, 'p_ex': 0.054794203490018845},\n",
       "  'MAPE_avg': {'p_or': 2163348340736.0, 'p_ex': 2163348340736.0},\n",
       "  'MAPE_90_avg': {'p_or': 0.008111423981247319, 'p_ex': 0.008111423981247319},\n",
       "  'MAPE_10_avg': {'p_or': 0.004253085751504593, 'p_ex': 0.004253085751504593}},\n",
       " 'Physics': {'LOSS_POS': {'violation_proportion': 0.0},\n",
       "  'DISC_LINES': {'p_or': 0.0, 'p_ex': 0.0, 'violation_proportion': 0.0},\n",
       "  'CHECK_LOSS': {'violation_percentage': 0.0},\n",
       "  'CHECK_GC': {'violation_percentage': 0.0,\n",
       "   'mae': 1.0942078e-05,\n",
       "   'wmape': 1.0},\n",
       "  'CHECK_LC': {'violation_percentage': 57.28785714285715,\n",
       "   'mae': 0.05239958356437928,\n",
       "   'mape': 0.0025080187147790292}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lips_irt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
